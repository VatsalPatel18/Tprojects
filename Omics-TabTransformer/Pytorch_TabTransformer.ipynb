{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0313b973-6089-4f68-9619-00ce13d19003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "config = {\n",
    "    \"NUMERIC_FEATURE_NAMES\": [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"],\n",
    "    \"CATEGORICAL_FEATURE_NAMES\": [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native_country\"],\n",
    "    \"TARGET_FEATURE_NAME\": \"income_bracket\",\n",
    "    \"TARGET_LABELS\": [\" <=50K\", \" >50K\"],\n",
    "    \"EMBEDDING_DIMS\": 16,\n",
    "    \"NUM_TRANSFORMER_BLOCKS\": 3,\n",
    "    \"NUM_HEADS\": 4,\n",
    "    \"DROPOUT_RATE\": 0.2,\n",
    "    \"MLP_HIDDEN_UNITS_FACTORS\": [2, 1],\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"WEIGHT_DECAY\": 0.0001,\n",
    "    \"BATCH_SIZE\": 265,\n",
    "    \"NUM_EPOCHS\": 15,\n",
    "    # \"TRAIN_DATA_URL\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    # \"TEST_DATA_URL\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "    # \"CSV_HEADER\": [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e48fd1-01b6-4cde-992b-d2e53adf4e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (4000, 14)\n",
      "Test dataset shape: (1000, 14)\n"
     ]
    }
   ],
   "source": [
    "# data_preparation.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_random_data(num_samples=5000):\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Generating random numerical data\n",
    "    age = np.random.randint(18, 70, num_samples)\n",
    "    education_num = np.random.randint(1, 16, num_samples)\n",
    "    capital_gain = np.random.randint(0, 10000, num_samples)\n",
    "    capital_loss = np.random.randint(0, 5000, num_samples)\n",
    "    hours_per_week = np.random.randint(1, 99, num_samples)\n",
    "    \n",
    "    # Generating random categorical data\n",
    "    workclass = np.random.choice(['Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov', 'Without-pay', 'Never-worked'], num_samples)\n",
    "    education = np.random.choice(['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool'], num_samples)\n",
    "    marital_status = np.random.choice(['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse'], num_samples)\n",
    "    occupation = np.random.choice(['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces'], num_samples)\n",
    "    relationship = np.random.choice(['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'], num_samples)\n",
    "    race = np.random.choice(['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'], num_samples)\n",
    "    gender = np.random.choice(['Male', 'Female'], num_samples)\n",
    "    native_country = np.random.choice(['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany', 'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico', 'Portugal', 'Ireland', 'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala', 'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador', 'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands'], num_samples)\n",
    "    \n",
    "    # Generating random target variable\n",
    "    income_bracket = np.random.choice([' <=50K', ' >50K'], num_samples)\n",
    "    \n",
    "    # Combining all features into a DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'age': age,\n",
    "        'workclass': workclass,\n",
    "        'education_num': education_num,\n",
    "        'education': education,\n",
    "        'marital_status': marital_status,\n",
    "        'occupation': occupation,\n",
    "        'relationship': relationship,\n",
    "        'race': race,\n",
    "        'gender': gender,\n",
    "        'capital_gain': capital_gain,\n",
    "        'capital_loss': capital_loss,\n",
    "        'hours_per_week': hours_per_week,\n",
    "        'native_country': native_country,\n",
    "        'income_bracket': income_bracket\n",
    "    })\n",
    "    \n",
    "    # Splitting the data into train and test sets\n",
    "    train_data = data.sample(frac=0.8, random_state=42)\n",
    "    test_data = data.drop(train_data.index)\n",
    "    \n",
    "    # Saving to CSV files\n",
    "    train_data.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "    test_data.to_csv(\"test_data.csv\", index=False, header=False)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_data, test_data = generate_random_data()\n",
    "    print(f\"Train dataset shape: {train_data.shape}\")\n",
    "    print(f\"Test dataset shape: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5d0399-6a1a-4df7-92dc-0bc572b1d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_csv('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dfb75b0-c7ce-4ffa-adc1-1e010da38710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_num</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>59</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>12</td>\n",
       "      <td>9th</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>5985</td>\n",
       "      <td>869</td>\n",
       "      <td>86</td>\n",
       "      <td>France</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>25</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>9</td>\n",
       "      <td>9th</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>9447</td>\n",
       "      <td>625</td>\n",
       "      <td>5</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>1st-4th</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>1550</td>\n",
       "      <td>2555</td>\n",
       "      <td>65</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>48</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>7</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>7001</td>\n",
       "      <td>1240</td>\n",
       "      <td>92</td>\n",
       "      <td>Honduras</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>53</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>11</td>\n",
       "      <td>9th</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>7420</td>\n",
       "      <td>3793</td>\n",
       "      <td>62</td>\n",
       "      <td>India</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>55</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>2</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>7098</td>\n",
       "      <td>4722</td>\n",
       "      <td>3</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>53</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>3</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>1845</td>\n",
       "      <td>3938</td>\n",
       "      <td>88</td>\n",
       "      <td>Laos</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>43</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>14</td>\n",
       "      <td>Preschool</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Priv-house-serv</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>2180</td>\n",
       "      <td>711</td>\n",
       "      <td>94</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>68</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>7</td>\n",
       "      <td>12th</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>8708</td>\n",
       "      <td>18</td>\n",
       "      <td>55</td>\n",
       "      <td>Italy</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>12</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-AF-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>3581</td>\n",
       "      <td>1928</td>\n",
       "      <td>64</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     workclass  education_num     education         marital_status  \\\n",
       "1501   59  Self-emp-inc             12           9th               Divorced   \n",
       "2586   25     Local-gov              9           9th               Divorced   \n",
       "2653   38       Private             13       1st-4th                Widowed   \n",
       "1055   48   Federal-gov              7          11th          Never-married   \n",
       "705    53     Local-gov             11           9th  Married-spouse-absent   \n",
       "...   ...           ...            ...           ...                    ...   \n",
       "3335   55     State-gov              2  Some-college  Married-spouse-absent   \n",
       "1920   53   Without-pay              3       7th-8th          Never-married   \n",
       "3715   43     Local-gov             14     Preschool  Married-spouse-absent   \n",
       "4646   68  Self-emp-inc              7          12th  Married-spouse-absent   \n",
       "946    38       Private             12  Some-college      Married-AF-spouse   \n",
       "\n",
       "             occupation    relationship                race  gender  \\\n",
       "1501    Exec-managerial  Other-relative               Black    Male   \n",
       "2586  Machine-op-inspct            Wife               Black  Female   \n",
       "2653    Exec-managerial       Unmarried               Other  Female   \n",
       "1055  Machine-op-inspct  Other-relative               Other    Male   \n",
       "705    Transport-moving       Own-child               Black  Female   \n",
       "...                 ...             ...                 ...     ...   \n",
       "3335  Handlers-cleaners       Unmarried               White  Female   \n",
       "1920       Craft-repair         Husband  Amer-Indian-Eskimo    Male   \n",
       "3715    Priv-house-serv            Wife               Black  Female   \n",
       "4646       Armed-Forces       Own-child  Amer-Indian-Eskimo    Male   \n",
       "946   Handlers-cleaners       Unmarried  Asian-Pac-Islander  Female   \n",
       "\n",
       "      capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
       "1501          5985           869              86         France          <=50K  \n",
       "2586          9447           625               5       Cambodia          <=50K  \n",
       "2653          1550          2555              65       Portugal          <=50K  \n",
       "1055          7001          1240              92       Honduras           >50K  \n",
       "705           7420          3793              62          India          <=50K  \n",
       "...            ...           ...             ...            ...            ...  \n",
       "3335          7098          4722               3          Haiti           >50K  \n",
       "1920          1845          3938              88           Laos           >50K  \n",
       "3715          2180           711              94        Vietnam           >50K  \n",
       "4646          8708            18              55          Italy           >50K  \n",
       "946           3581          1928              64       Portugal          <=50K  \n",
       "\n",
       "[4000 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055dd6f-0391-4b08-be6c-2c8217b580cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "998e6ab2-9e13-4050-ac69-898226730c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabtransformer.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from config import config\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, numerical_features, categorical_features, target):\n",
    "        self.numerical_data = data[numerical_features].values.astype(np.float32)\n",
    "        self.categorical_data = data[categorical_features].apply(lambda x: x.astype('category').cat.codes).values\n",
    "        self.labels = LabelEncoder().fit_transform(data[target])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'numerical_data': torch.tensor(self.numerical_data[idx]),\n",
    "            'categorical_data': torch.tensor(self.categorical_data[idx], dtype=torch.long),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d0baab9-ea42-4d99-8d6d-501f28f9b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, dropout):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_size, num_heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, embed_size)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attention_output, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attention_output))\n",
    "        feed_forward_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(feed_forward_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1cea5bb-8b33-4e38-8b37-a73279dfb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, num_categories, num_numerical, embed_size, num_heads, num_blocks, dropout, mlp_hidden_units_factors):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, embed_size) for categories in num_categories])\n",
    "        self.transformer_blocks = nn.ModuleList([TransformerBlock(embed_size, num_heads, dropout) for _ in range(num_blocks)])\n",
    "        self.mlp_input_size = len(num_categories) * embed_size + num_numerical\n",
    "        mlp_hidden_units = [factor * self.mlp_input_size for factor in mlp_hidden_units_factors]\n",
    "        self.mlp = self._create_mlp(mlp_hidden_units, dropout)\n",
    "        self.output_layer = nn.Linear(mlp_hidden_units[-1], 1)\n",
    "        \n",
    "    def _create_mlp(self, hidden_units, dropout):\n",
    "        layers = []\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(self.mlp_input_size, units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            self.mlp_input_size = units\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, numerical_data, categorical_data):\n",
    "        embeddings = [embed(categorical_data[:, i]) for i, embed in enumerate(self.embeddings)]\n",
    "        x = torch.stack(embeddings, dim=1)  # Stack along the new dimension\n",
    "        x = x.permute(1, 0, 2)  # Permute to (sequence_length, batch_size, embed_dim)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        x = x.permute(1, 0, 2).contiguous().view(x.size(1), -1)  # Reshape back and align the batch size\n",
    "        x = torch.cat([x, numerical_data], dim=1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.output_layer(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe53c72f-c74a-4958-ad43-cd82acb13f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 44.3562, Val Loss: 45.3981, Val Acc: 0.5064\n",
      "Epoch 2/15, Loss: 33.1119, Val Loss: 34.9974, Val Acc: 0.5064\n",
      "Epoch 3/15, Loss: 18.1953, Val Loss: 19.0717, Val Acc: 0.5062\n",
      "Epoch 4/15, Loss: 1.0594, Val Loss: 1.1065, Val Acc: 0.5070\n",
      "Epoch 5/15, Loss: 0.6983, Val Loss: 0.6985, Val Acc: 0.5018\n",
      "Epoch 6/15, Loss: 0.6939, Val Loss: 0.6935, Val Acc: 0.4988\n",
      "Epoch 7/15, Loss: 0.6941, Val Loss: 0.6927, Val Acc: 0.5051\n",
      "Epoch 8/15, Loss: 0.6937, Val Loss: 0.6928, Val Acc: 0.5066\n",
      "Epoch 9/15, Loss: 0.6932, Val Loss: 0.6930, Val Acc: 0.5074\n",
      "Epoch 10/15, Loss: 0.6932, Val Loss: 0.6930, Val Acc: 0.5084\n",
      "Epoch 11/15, Loss: 0.6932, Val Loss: 0.6929, Val Acc: 0.5062\n",
      "Epoch 12/15, Loss: 0.6937, Val Loss: 0.6928, Val Acc: 0.5075\n",
      "Epoch 13/15, Loss: 0.6937, Val Loss: 0.6928, Val Acc: 0.5104\n",
      "Epoch 14/15, Loss: 0.6933, Val Loss: 0.6929, Val Acc: 0.5074\n",
      "Epoch 15/15, Loss: 0.6930, Val Loss: 0.6930, Val Acc: 0.5117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, lr, weight_decay):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            numerical_data = batch['numerical_data']\n",
    "            categorical_data = batch['categorical_data']\n",
    "            labels = batch['label'].unsqueeze(1).float()\n",
    "            \n",
    "            outputs = model(numerical_data, categorical_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                numerical_data = batch['numerical_data']\n",
    "                categorical_data = batch['categorical_data']\n",
    "                labels = batch['label'].unsqueeze(1).float()\n",
    "                \n",
    "                outputs = model(numerical_data, categorical_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                predictions = (outputs > 0.5).float()\n",
    "                val_acc += (predictions == labels).float().mean()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc/len(val_loader):.4f}')\n",
    "\n",
    "def main():\n",
    "    # Generate random dataset\n",
    "    train_data, test_data = generate_random_data()\n",
    "    \n",
    "    # Prepare datasets\n",
    "    train_dataset = TabularDataset(train_data, config[\"NUMERIC_FEATURE_NAMES\"], config[\"CATEGORICAL_FEATURE_NAMES\"], config[\"TARGET_FEATURE_NAME\"])\n",
    "    test_dataset = TabularDataset(test_data, config[\"NUMERIC_FEATURE_NAMES\"], config[\"CATEGORICAL_FEATURE_NAMES\"], config[\"TARGET_FEATURE_NAME\"])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=False)\n",
    "    \n",
    "    # Determine number of unique categories for each categorical feature\n",
    "    num_categories = [len(train_data[feature].unique()) for feature in config[\"CATEGORICAL_FEATURE_NAMES\"]]\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = TabTransformer(num_categories, len(config[\"NUMERIC_FEATURE_NAMES\"]), config[\"EMBEDDING_DIMS\"], config[\"NUM_HEADS\"], config[\"NUM_TRANSFORMER_BLOCKS\"], config[\"DROPOUT_RATE\"], config[\"MLP_HIDDEN_UNITS_FACTORS\"])\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, train_loader, test_loader, config[\"NUM_EPOCHS\"], config[\"LEARNING_RATE\"], config[\"WEIGHT_DECAY\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c1d19-4dde-4509-a956-2e63c4b27b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
