{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16827b73-1fd8-42d7-8558-9a25462f66a6",
   "metadata": {
    "id": "16827b73-1fd8-42d7-8558-9a25462f66a6"
   },
   "source": [
    "# Phi-3-TinyStories\n",
    "\n",
    "Author: [Han@Jina AI](https://twitter.com/hxiao)\n",
    "\n",
    "This 50M-parameter model reconfigures `Phi-3-mini-128k-instruct` (3.8B parameters) by following the guidelines provided by the [Super Tiny Language Models](https://arxiv.org/abs/2405.14159) paper from A*STAR. It is then trained from scratch on [Microsoft's TinyStories dataset](https://arxiv.org/abs/2305.07759).\n",
    "\n",
    "Note:\n",
    "- After the model creation, I copied weights from the pretrained `Phi-3-mini-128k-instruct` model to the new model by truncating at the tails. This heuristic serves as a good initialization point for training.\n",
    "- The A*STAR paper uses Llama2 as the base, so the tokenizer and activation function are different.\n",
    "- Since the original TinyStories dataset does not contain instruction-following data, for instruction tuning, this notebook uses one fixed instruction: `tell me a story`. A better way would be to [generate synthetic instructions using TinyStories metadata](https://huggingface.co/datasets/roneneldan/TinyStories/discussions/11).\n",
    "- Given the model's size and the very basic training, I don't expect it to generalize well to any out-of-domain data. At best, it may generalize to other fairy tales (i.e., out-of-distribution).\n",
    "- For an untrained 50M-parameter version, [please look at this notebook](https://colab.research.google.com/drive/188RpybbauEJKSIRPGL3RZi4Lk66HfBJj).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd071c26-c01f-4248-ab53-496590299ff8",
   "metadata": {
    "id": "bd071c26-c01f-4248-ab53-496590299ff8",
    "outputId": "d17aaf9d-88f7-4a44-fcbe-216c6b545c69",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/han/.local/lib/python3.10/site-packages (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/han/.local/lib/python3.10/site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/han/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/han/.local/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/han/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/han/.local/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/han/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/han/.local/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/han/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/han/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/han/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in /home/han/.local/lib/python3.10/site-packages (0.23.1)\n",
      "Requirement already satisfied: peft in /home/han/.local/lib/python3.10/site-packages (0.11.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/han/.local/lib/python3.10/site-packages (0.43.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface_hub) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/han/.local/lib/python3.10/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/python3/dist-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface_hub) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/han/.local/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/han/.local/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/han/.local/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/han/.local/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: psutil in /home/han/.local/lib/python3.10/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/han/.local/lib/python3.10/site-packages (from peft) (2.3.0)\n",
      "Requirement already satisfied: transformers in /home/han/.local/lib/python3.10/site-packages (from peft) (4.41.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/han/.local/lib/python3.10/site-packages (from peft) (0.30.1)\n",
      "Requirement already satisfied: safetensors in /home/han/.local/lib/python3.10/site-packages (from peft) (0.4.2)\n",
      "Requirement already satisfied: sympy in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/han/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/han/.local/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2020.6.20)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/han/.local/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/han/.local/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/han/.local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/han/.local/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trl in /home/han/.local/lib/python3.10/site-packages (0.8.6)\n",
      "Requirement already satisfied: xformers in /home/han/.local/lib/python3.10/site-packages (0.0.26.post1)\n",
      "Requirement already satisfied: flash-attn in /home/han/.local/lib/python3.10/site-packages (2.5.8)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/han/.local/lib/python3.10/site-packages (from trl) (2.3.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/han/.local/lib/python3.10/site-packages (from trl) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/han/.local/lib/python3.10/site-packages (from trl) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /home/han/.local/lib/python3.10/site-packages (from trl) (0.30.1)\n",
      "Requirement already satisfied: datasets in /home/han/.local/lib/python3.10/site-packages (from trl) (2.14.7)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/han/.local/lib/python3.10/site-packages (from trl) (0.8.4)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=1.4.0->trl) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/han/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/han/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.99)\n",
      "Requirement already satisfied: einops in /home/han/.local/lib/python3.10/site-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from flash-attn) (21.3)\n",
      "Requirement already satisfied: ninja in /home/han/.local/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/han/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.31.0->trl) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/han/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/han/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/han/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/han/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/han/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.2)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/han/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/han/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/han/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in /home/han/.local/lib/python3.10/site-packages (from accelerate->trl) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/han/.local/lib/python3.10/site-packages (from datasets->trl) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/han/.local/lib/python3.10/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/han/.local/lib/python3.10/site-packages (from datasets->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/han/.local/lib/python3.10/site-packages (from datasets->trl) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /home/han/.local/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/han/.local/lib/python3.10/site-packages (from datasets->trl) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/han/.local/lib/python3.10/site-packages (from datasets->trl) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/han/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/han/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/han/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/han/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/han/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/han/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/han/.local/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers>=4.31.0->trl) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers>=4.31.0->trl) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers>=4.31.0->trl) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/han/.local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/han/.local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/han/.local/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/han/.local/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets->trl) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/han/.local/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/han/.local/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/han/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers\n",
    "!pip install huggingface_hub peft bitsandbytes\n",
    "!pip install trl xformers flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0d6dd-f4d9-4554-908c-223635e43bcb",
   "metadata": {
    "id": "a3b0d6dd-f4d9-4554-908c-223635e43bcb",
    "outputId": "c97157d2-652b-469f-ee8a-e3507249f279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 27 21:03:21 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 41%   48C    P8              37W / 350W |     28MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 30%   37C    P8              39W / 350W |     12MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 3090        On  | 00000000:4C:00.0 Off |                  N/A |\n",
      "| 46%   49C    P8              30W / 350W |     12MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1793      G   /usr/lib/xorg/Xorg                            9MiB |\n",
      "|    0   N/A  N/A      1942      G   /usr/bin/gnome-shell                          8MiB |\n",
      "|    1   N/A  N/A      1793      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    2   N/A  N/A      1793      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a45bb-75ce-4946-aabe-724a50b8d5d0",
   "metadata": {
    "id": "592a45bb-75ce-4946-aabe-724a50b8d5d0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535480c-ec13-42a7-b6a5-88781d8d57b0",
   "metadata": {
    "id": "a535480c-ec13-42a7-b6a5-88781d8d57b0",
    "outputId": "aa1920d0-ab26-4696-996d-7c190554856a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import is_flash_attn_2_available\n",
    "is_flash_attn_2_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61389612-ae0b-4e00-b676-970b7f9a65ba",
   "metadata": {
    "id": "61389612-ae0b-4e00-b676-970b7f9a65ba"
   },
   "outputs": [],
   "source": [
    "def count_model_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f8596-7024-4344-bdd9-e0706ab742b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "3ce0d23a21614df297393cb2fca1c57f",
      "9b3de0d1347247758170f548b493d595",
      "eec0c13e4fcd45ed93b6e40d03561bec",
      "810a95a2db654fbdbf0fa84d1acb9013",
      "67ec195204e544f29ab82229bfcb8c0d",
      "352a2b8937604cd995ff62f7d6952eff",
      "19ecd203d4b3468e830f55a0bde35ff5",
      "8554ece393cd4b3fb95c8c0e8c862c74",
      "b8fd848677a44075af27cda9c87976c8",
      "16985ec5ba7a4ffb98fdce96fbae3b9b",
      "59ae998eb2704dfea548818d709f6929",
      "b4435abca7654a2da736742245ac4fee",
      "02b0fcac76c947d5841cc7619b414b3d",
      "2be36c844a6742b5a8cb2e80f86aee35",
      "4906dabe8c044b6d9579ad60bc596b1c",
      "f40be4e7be814ee5977a74bb8915fa46",
      "b9f780ef1a024e5a929e2c2f689fd154",
      "70c62d0cac644be2b1055d22c7222969",
      "70c6098371264b519ec201d6d05368f6",
      "6d56256f76314aa3939494bbf582590e",
      "fee4c940954f481889ff641a7db5239f",
      "cab68b0239664795b8b290079df172d9"
     ]
    },
    "id": "c77f8596-7024-4344-bdd9-e0706ab742b0",
    "outputId": "7139241e-78d4-4f07-ebcf-40fb889e6237"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce0d23a21614df297393cb2fca1c57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4435abca7654a2da736742245ac4fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "MAX_SEQ_LENGTH = 512\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\", torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation='flash_attention_2')\n",
    "config.max_position_embeddings = MAX_SEQ_LENGTH   # in the original Phi3-128k this was 131072 (2**17), A*Star sets this to 512. Note this wont change the size of the parameters but does save a LOT VRAM during training.\n",
    "config.num_hidden_layers = 10\n",
    "config.tie_word_embeddings = True\n",
    "config.hidden_size = 512\n",
    "config.intermediate_size = 1536\n",
    "config.num_attention_heads = 16\n",
    "config.num_key_value_heads = 16\n",
    "\n",
    "# Adjust the rope scaling factors\n",
    "required_length = config.hidden_size // (config.num_attention_heads * 2)\n",
    "config.rope_scaling['long_factor'] = config.rope_scaling['long_factor'][:required_length]\n",
    "config.rope_scaling['short_factor'] = config.rope_scaling['short_factor'][:required_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c5620-0c8e-487e-a449-8e71e2e82d50",
   "metadata": {
    "id": "962c5620-0c8e-487e-a449-8e71e2e82d50"
   },
   "outputs": [],
   "source": [
    "# Initialize a new model with the modified configuration\n",
    "new_model = AutoModelForCausalLM.from_config(config, torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation='flash_attention_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938dadce-923b-40fc-bfb4-f7023875cfc8",
   "metadata": {
    "id": "938dadce-923b-40fc-bfb4-f7023875cfc8",
    "outputId": "7d445671-d1e8-44dd-d6d7-4d579d9a4d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phi3Config {\n",
       "  \"_name_or_path\": \"microsoft/Phi-3-mini-128k-instruct\",\n",
       "  \"architectures\": [\n",
       "    \"Phi3ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n",
       "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
       "  },\n",
       "  \"bos_token_id\": 1,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": 32000,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 512,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1536,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"phi3\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 10,\n",
       "  \"num_key_value_heads\": 16,\n",
       "  \"original_max_position_embeddings\": 4096,\n",
       "  \"pad_token_id\": 32000,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"long_factor\": [\n",
       "      1.0299999713897705,\n",
       "      1.0499999523162842,\n",
       "      1.0499999523162842,\n",
       "      1.0799999237060547,\n",
       "      1.2299998998641968,\n",
       "      1.2299998998641968,\n",
       "      1.2999999523162842,\n",
       "      1.4499999284744263,\n",
       "      1.5999999046325684,\n",
       "      1.6499998569488525,\n",
       "      1.8999998569488525,\n",
       "      2.859999895095825,\n",
       "      3.68999981880188,\n",
       "      5.419999599456787,\n",
       "      5.489999771118164,\n",
       "      5.489999771118164\n",
       "    ],\n",
       "    \"short_factor\": [\n",
       "      1.05,\n",
       "      1.05,\n",
       "      1.05,\n",
       "      1.1,\n",
       "      1.1,\n",
       "      1.1500000000000001,\n",
       "      1.2000000000000002,\n",
       "      1.2500000000000002,\n",
       "      1.3000000000000003,\n",
       "      1.3500000000000003,\n",
       "      1.5000000000000004,\n",
       "      2.000000000000001,\n",
       "      2.000000000000001,\n",
       "      2.000000000000001,\n",
       "      2.000000000000001,\n",
       "      2.000000000000001\n",
       "    ],\n",
       "    \"type\": \"su\"\n",
       "  },\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 262144,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.41.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32064\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7cf8b-d328-48ff-a7e6-753ed19078ee",
   "metadata": {
    "id": "6bc7cf8b-d328-48ff-a7e6-753ed19078ee",
    "outputId": "e0e9420b-0623-4de1-c7ae-c92ddd6d1ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 66,923,008\n",
      "Trainable parameters: 66,923,008\n"
     ]
    }
   ],
   "source": [
    "count_model_parameters(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c4e38-e0b0-4ded-8d93-b152c5039abb",
   "metadata": {
    "id": "ad2c4e38-e0b0-4ded-8d93-b152c5039abb"
   },
   "source": [
    "# (optional) Copy weights from pretrained models to the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeda727-c7dd-4c00-ba2a-64dca19e5a52",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fca1fb94e8bc4527a54c05bea0e65662"
     ]
    },
    "id": "5eeda727-c7dd-4c00-ba2a-64dca19e5a52",
    "outputId": "bdee020b-3c8f-4476-9f28-b740b90dc716"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca1fb94e8bc4527a54c05bea0e65662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight get partial copied\n",
      "model.layers.0.self_attn.o_proj.weight get partial copied\n",
      "model.layers.0.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.0.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.0.mlp.down_proj.weight get partial copied\n",
      "model.layers.0.input_layernorm.weight get partial copied\n",
      "model.layers.0.post_attention_layernorm.weight get partial copied\n",
      "model.layers.1.self_attn.o_proj.weight get partial copied\n",
      "model.layers.1.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.1.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.1.mlp.down_proj.weight get partial copied\n",
      "model.layers.1.input_layernorm.weight get partial copied\n",
      "model.layers.1.post_attention_layernorm.weight get partial copied\n",
      "model.layers.2.self_attn.o_proj.weight get partial copied\n",
      "model.layers.2.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.2.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.2.mlp.down_proj.weight get partial copied\n",
      "model.layers.2.input_layernorm.weight get partial copied\n",
      "model.layers.2.post_attention_layernorm.weight get partial copied\n",
      "model.layers.3.self_attn.o_proj.weight get partial copied\n",
      "model.layers.3.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.3.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.3.mlp.down_proj.weight get partial copied\n",
      "model.layers.3.input_layernorm.weight get partial copied\n",
      "model.layers.3.post_attention_layernorm.weight get partial copied\n",
      "model.layers.4.self_attn.o_proj.weight get partial copied\n",
      "model.layers.4.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.4.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.4.mlp.down_proj.weight get partial copied\n",
      "model.layers.4.input_layernorm.weight get partial copied\n",
      "model.layers.4.post_attention_layernorm.weight get partial copied\n",
      "model.layers.5.self_attn.o_proj.weight get partial copied\n",
      "model.layers.5.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.5.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.5.mlp.down_proj.weight get partial copied\n",
      "model.layers.5.input_layernorm.weight get partial copied\n",
      "model.layers.5.post_attention_layernorm.weight get partial copied\n",
      "model.layers.6.self_attn.o_proj.weight get partial copied\n",
      "model.layers.6.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.6.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.6.mlp.down_proj.weight get partial copied\n",
      "model.layers.6.input_layernorm.weight get partial copied\n",
      "model.layers.6.post_attention_layernorm.weight get partial copied\n",
      "model.layers.7.self_attn.o_proj.weight get partial copied\n",
      "model.layers.7.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.7.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.7.mlp.down_proj.weight get partial copied\n",
      "model.layers.7.input_layernorm.weight get partial copied\n",
      "model.layers.7.post_attention_layernorm.weight get partial copied\n",
      "model.layers.8.self_attn.o_proj.weight get partial copied\n",
      "model.layers.8.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.8.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.8.mlp.down_proj.weight get partial copied\n",
      "model.layers.8.input_layernorm.weight get partial copied\n",
      "model.layers.8.post_attention_layernorm.weight get partial copied\n",
      "model.layers.9.self_attn.o_proj.weight get partial copied\n",
      "model.layers.9.self_attn.qkv_proj.weight get partial copied\n",
      "model.layers.9.mlp.gate_up_proj.weight get partial copied\n",
      "model.layers.9.mlp.down_proj.weight get partial copied\n",
      "model.layers.9.input_layernorm.weight get partial copied\n",
      "model.layers.9.post_attention_layernorm.weight get partial copied\n",
      "model.norm.weight get partial copied\n",
      "lm_head.weight get partial copied\n",
      "pretrained weights are copied to the new model\n"
     ]
    }
   ],
   "source": [
    "# General function to copy tensor with shape handling\n",
    "def copy_tensor(pre_tensor, new_tensor):\n",
    "    # Determine the slice indices for each dimension\n",
    "    slices = tuple(slice(-min(pre_dim, new_dim), None) if pre_dim != new_dim else slice(None)\n",
    "                   for pre_dim, new_dim in zip(pre_tensor.shape, new_tensor.shape))\n",
    "\n",
    "    # Copy the relevant sub-tensor\n",
    "    new_tensor[slices] = pre_tensor[slices]\n",
    "    return new_tensor\n",
    "\n",
    "# Function to copy weights with generalized shape handling\n",
    "def copy_weights(pretrained_model, new_model):\n",
    "    pretrained_state_dict = pretrained_model.state_dict()\n",
    "    new_state_dict = new_model.state_dict()\n",
    "\n",
    "    for key in new_state_dict.keys():\n",
    "        if key in pretrained_state_dict:\n",
    "            pre_tensor = pretrained_state_dict[key]\n",
    "            new_tensor = new_state_dict[key]\n",
    "            if new_tensor.shape == pre_tensor.shape:\n",
    "                new_state_dict[key] = pre_tensor\n",
    "                print(f'{key} get fully copied')\n",
    "            else:\n",
    "                new_state_dict[key] = copy_tensor(pre_tensor, new_tensor)\n",
    "                print(f'{key} get partial copied')\n",
    "        else:\n",
    "            print(f\"Skipping {key} as it is not present in the pretrained model.\")\n",
    "\n",
    "    new_model.load_state_dict(new_state_dict)\n",
    "    print('pretrained weights are copied to the new model')\n",
    "    return new_model\n",
    "\n",
    "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation='flash_attention_2'\n",
    ")\n",
    "# Copy weights from the pretrained model to the new model\n",
    "new_model = copy_weights(pretrained_model, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224c4b0-dcdb-4827-92df-fb64c298f453",
   "metadata": {
    "id": "6224c4b0-dcdb-4827-92df-fb64c298f453",
    "outputId": "ae91ae8a-ab3c-4d73-eae8-8dbee1bc52a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/han/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaenaCountryenaenaenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryenaCountryCountryCountryCountryenaCountryenaCountryCountryCountryCountryCountryCountryCountryenaCountryCountryenaCountryCountryCountryCountryCountryCountryenaCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryenaCountryCountryCountryenaCountryCountryenaCountryCountryCountryCountryenaCountryCountryCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryenaCountryCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryenaCountryCountryCountryCountryCountryCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryenaCountryenaCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryenaCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountryCountry\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\"+\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
    "new_model.to('cuda')\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''tell me a story'''},\n",
    "]\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=new_model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2aa69-169a-4920-9c0c-0e945412d090",
   "metadata": {
    "id": "17d2aa69-169a-4920-9c0c-0e945412d090",
    "outputId": "e9353c12-c2d4-4803-ef01-49f73c1fd6d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "/home/han/.local/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a1329-bd1b-4c67-a4aa-186ba924e50f",
   "metadata": {
    "id": "2d4a1329-bd1b-4c67-a4aa-186ba924e50f",
    "outputId": "cc8ce208-cf39-4466-de28-927d94282905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2119719\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 21990\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807361af-a642-4d3b-a81f-9e0aa1c313f4",
   "metadata": {
    "id": "807361af-a642-4d3b-a81f-9e0aa1c313f4"
   },
   "outputs": [],
   "source": [
    "def formatting_prompts_func(story):\n",
    "    # note that the original tinystories dataset is NOT instruction-followin, so here for convience i just fix the instruction to tell me a story.\n",
    "    text = f\"<|user|>tell me a story<|end|><|assistant|>{story['text']}<|endoftext|>\"\n",
    "    return {\"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cb448-4521-42ba-bf5e-3afa8863c1c9",
   "metadata": {
    "id": "5d2cb448-4521-42ba-bf5e-3afa8863c1c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "per_device_train_batch_size = 64  # adjust this if u r running on bigger/smaller VRAM, for 3090 24GB this seems fine\n",
    "gradient_accumulation_steps = 2\n",
    "num_train_epochs = 1\n",
    "\n",
    "args = TrainingArguments(\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    gradient_checkpointing=True,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=-1,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    output_dir='phi-3-tinystories',\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    bf16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354c907-8418-4c81-925f-49e5afc17df8",
   "metadata": {
    "id": "8354c907-8418-4c81-925f-49e5afc17df8",
    "outputId": "579b57ac-143a-42d1-e679-562c744cf59e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/han/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/han/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='901' max='16560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  901/16560 30:24 < 8:49:35, 0.49 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.055100</td>\n",
       "      <td>6.335695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.057800</td>\n",
       "      <td>5.799569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.619900</td>\n",
       "      <td>5.442186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.335300</td>\n",
       "      <td>5.218199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.146100</td>\n",
       "      <td>5.057658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.008800</td>\n",
       "      <td>4.939473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.899400</td>\n",
       "      <td>4.850070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.819500</td>\n",
       "      <td>4.785405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2187' max='2749' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2187/2749 00:45 < 00:11, 47.80 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=new_model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    formatting_func=formatting_prompts_func\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daf4d9-90bd-410c-a530-8fe3be6667a4",
   "metadata": {
    "id": "20daf4d9-90bd-410c-a530-8fe3be6667a4"
   },
   "outputs": [],
   "source": [
    "output = pipe(messages, **generation_args)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6fc410-bf24-4eda-a3ed-1b8b9adc2626",
   "metadata": {
    "id": "ae6fc410-bf24-4eda-a3ed-1b8b9adc2626"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02b0fcac76c947d5841cc7619b414b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9f780ef1a024e5a929e2c2f689fd154",
      "placeholder": "​",
      "style": "IPY_MODEL_70c62d0cac644be2b1055d22c7222969",
      "value": "configuration_phi3.py: 100%"
     }
    },
    "16985ec5ba7a4ffb98fdce96fbae3b9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19ecd203d4b3468e830f55a0bde35ff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2be36c844a6742b5a8cb2e80f86aee35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70c6098371264b519ec201d6d05368f6",
      "max": 10411,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d56256f76314aa3939494bbf582590e",
      "value": 10411
     }
    },
    "352a2b8937604cd995ff62f7d6952eff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ce0d23a21614df297393cb2fca1c57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b3de0d1347247758170f548b493d595",
       "IPY_MODEL_eec0c13e4fcd45ed93b6e40d03561bec",
       "IPY_MODEL_810a95a2db654fbdbf0fa84d1acb9013"
      ],
      "layout": "IPY_MODEL_67ec195204e544f29ab82229bfcb8c0d"
     }
    },
    "4906dabe8c044b6d9579ad60bc596b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fee4c940954f481889ff641a7db5239f",
      "placeholder": "​",
      "style": "IPY_MODEL_cab68b0239664795b8b290079df172d9",
      "value": " 10.4k/10.4k [00:00&lt;00:00, 230kB/s]"
     }
    },
    "59ae998eb2704dfea548818d709f6929": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67ec195204e544f29ab82229bfcb8c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d56256f76314aa3939494bbf582590e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "70c6098371264b519ec201d6d05368f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70c62d0cac644be2b1055d22c7222969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "810a95a2db654fbdbf0fa84d1acb9013": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16985ec5ba7a4ffb98fdce96fbae3b9b",
      "placeholder": "​",
      "style": "IPY_MODEL_59ae998eb2704dfea548818d709f6929",
      "value": " 3.35k/3.35k [00:00&lt;00:00, 62.4kB/s]"
     }
    },
    "8554ece393cd4b3fb95c8c0e8c862c74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b3de0d1347247758170f548b493d595": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_352a2b8937604cd995ff62f7d6952eff",
      "placeholder": "​",
      "style": "IPY_MODEL_19ecd203d4b3468e830f55a0bde35ff5",
      "value": "config.json: 100%"
     }
    },
    "b4435abca7654a2da736742245ac4fee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02b0fcac76c947d5841cc7619b414b3d",
       "IPY_MODEL_2be36c844a6742b5a8cb2e80f86aee35",
       "IPY_MODEL_4906dabe8c044b6d9579ad60bc596b1c"
      ],
      "layout": "IPY_MODEL_f40be4e7be814ee5977a74bb8915fa46"
     }
    },
    "b8fd848677a44075af27cda9c87976c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9f780ef1a024e5a929e2c2f689fd154": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cab68b0239664795b8b290079df172d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eec0c13e4fcd45ed93b6e40d03561bec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8554ece393cd4b3fb95c8c0e8c862c74",
      "max": 3353,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8fd848677a44075af27cda9c87976c8",
      "value": 3353
     }
    },
    "f40be4e7be814ee5977a74bb8915fa46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fee4c940954f481889ff641a7db5239f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
